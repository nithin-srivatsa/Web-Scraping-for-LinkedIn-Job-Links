{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithin-srivatsa/Web-Scraping-for-LinkedIn-Job-Links/blob/main/Linkedin_Data_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552a07ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "552a07ce",
        "outputId": "218c3395-d0c0-482e-91ec-448fc953e161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a LinkedIn job URL (or enter \"done\" to finish, DO NOT press enter without inputting text): https://www.linkedin.com/jobs/view/3469052453\n"
          ]
        }
      ],
      "source": [
        "#Create a file, add the path where it says \"file path\" in the end, and then press shift enter.\n",
        "#Keep pasting the LinkedIn URLS, and it's going to enter the Name of the Company, name of the job, and when you applied!\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "def get_job_info(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    job_title = soup.find('h1', {'class': 'topcard__title'})\n",
        "    company = soup.find('a', {'class': 'topcard__org-name-link'})\n",
        "    location = soup.find('span', {'class': 'topcard__flavor'})\n",
        "    if job_title and company and location:\n",
        "        return (job_title.text.strip(), company.text.strip(), location.text.strip())\n",
        "    return None\n",
        "\n",
        "def process_job_urls(urls):\n",
        "    job_titles = []\n",
        "    companies = []\n",
        "    locations = []\n",
        "    dates = []\n",
        "    for url in urls:\n",
        "        job_info = get_job_info(url)\n",
        "        if job_info:\n",
        "            job_titles.append(job_info[0])\n",
        "            companies.append(job_info[1])\n",
        "            locations.append(job_info[2])\n",
        "            dates.append(datetime.date.today())\n",
        "    df = pd.DataFrame({'Job Title': job_titles, 'Company': companies, 'Location': locations, 'Date': dates})\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    urls = []\n",
        "    while True:\n",
        "        url = input('Enter a LinkedIn job URL (or enter \"done\" to finish, DO NOT press enter without inputting text): ')\n",
        "        if url == 'done':\n",
        "            break\n",
        "        urls.append(url)\n",
        "    df = process_job_urls(urls)\n",
        "    file_path = 'Downloads\\LinkedIn_Final.xlsx'\n",
        "    df.to_excel(file_path, index=False, encoding='utf-8')\n",
        "    print(f'The job titles, companies, locations, and dates have been written to {file_path}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}